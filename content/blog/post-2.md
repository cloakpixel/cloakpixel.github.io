---
title: "equalAIs"
date: 2018-04-20T15:40:24+06:00
image : "images/blog/equalais_shell.png"
# author
author : ["equalAIs"]
# categories
categories: ["tools"]
tags: ["tools"]
# meta description
description: "Overview of equalAIs"
# save as draft
draft: false
---

Concerned by the unregulated application of facial recognition technologies, a team of fellows from the 2018 Assembly program at the Berkman Klein Center created [equalAIs](https://equalais.media.mit.edu/), a digital mask for photos that fights pervasive surveillance and helps protect civil liberties.

The tool embeds an adversarial attack in an image, preventing face detection systems from finding faces in the image. The tool also embeds a visible watermark and encodes a steganographic message that both communicate a lack of consent to face recognition processing.

The open-source [repository](https://github.com/equalais/equalais_app) provides documentation and instructions for training and using face detection adversarial attack.
